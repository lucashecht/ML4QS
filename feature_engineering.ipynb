{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def readtcx(path):\n",
    "    heartrate_data = []\n",
    "    with open(path) as xml_file:\n",
    "        xml_str = xml_file.read()\n",
    "        xml_str = re.sub(' xmlns=\"[^\"]+\"', '', xml_str, count=1)\n",
    "        root = ET.fromstring(xml_str)\n",
    "        activities = root.findall('.//Activity')\n",
    "        for activity in activities:\n",
    "            tracking_points = activity.findall('.//Trackpoint')\n",
    "            for tracking_point in list(tracking_points):\n",
    "                children = list(tracking_point)\n",
    "                time = datetime.strptime(children[0].text, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                hr = list(tracking_point.find('HeartRateBpm'))[0].text\n",
    "                heartrate_data.append([time, hr])\n",
    "    df = pd.DataFrame(heartrate_data, columns=['time', 'hr'])\n",
    "    #df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartrate_data = readtcx(\"../data/Lucas/walking1/walking1.tcx\")\n",
    "heartrate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff(df):\n",
    "    res = []\n",
    "    for i in range(len(df[\"Time (s)\"]) - 1):\n",
    "        val1 = df[\"Time (s)\"][i]\n",
    "        val2 = df[\"Time (s)\"][i + 1]\n",
    "        \n",
    "        res.append(val2 - val1)\n",
    "    return mean(res)\n",
    "\n",
    "def read_phyphox(parent_dir):\n",
    "    acc = pd.read_csv(os.path.join(parent_dir, \"Accelerometer.csv\"))\n",
    "    gyro = pd.read_csv(os.path.join(parent_dir, \"Gyroscope.csv\"))\n",
    "    loc = pd.read_csv(os.path.join(parent_dir, \"Location.csv\"))\n",
    "        \n",
    "    data_len = min(len(acc), len(gyro))\n",
    "    acc = acc[0:data_len]\n",
    "    gyro = gyro[0:data_len]\n",
    "        \n",
    "    time_step = mean([time_diff(acc), time_diff(gyro)])\n",
    "    \n",
    "    for i in range(data_len):\n",
    "        time = time_step * i\n",
    "        acc[\"Time (s)\"][i] = time\n",
    "        gyro[\"Time (s)\"][i] = time\n",
    "    \n",
    "    acc.set_index('Time (s)', inplace=True)\n",
    "    gyro.set_index('Time (s)', inplace=True)\n",
    "    loc.set_index('Time (s)', inplace=True)\n",
    "        \n",
    "            \n",
    "    merged = acc.join(gyro, how=\"outer\")\n",
    "    merged = pd.concat([merged, loc]).sort_index().interpolate()\n",
    "    \n",
    "    # Rename columns\n",
    "    merged.index.names = [\"time\"]\n",
    "    merged.rename(inplace=True, columns={\n",
    "        \"Acceleration x (m/s^2)\": \"acceleration_x\",\n",
    "        \"Acceleration y (m/s^2)\": \"acceleration_y\",\n",
    "        \"Acceleration z (m/s^2)\": \"acceleration_z\",\n",
    "        \"Gyroscope x (rad/s)\": \"gyroscope_x\",\n",
    "        \"Gyroscope y (rad/s)\": \"gyroscope_y\",\n",
    "        \"Gyroscope z (rad/s)\": \"gyroscope_z\",\n",
    "        \"Latitude (°)\": \"latitude\",\n",
    "        \"Longitude (°)\": \"longitude\",\n",
    "        \"Height (m)\": \"height\",\n",
    "        \"Velocity (m/s)\": \"velocity\",\n",
    "        \"Direction (°)\": \"direction\",\n",
    "        \"Horizontal Accuracy (m)\": \"h_accuracy\",\n",
    "        \"Vertical Accuracy (m)\": \"v_accuracy\",\n",
    "\n",
    "    })\n",
    "    merged = merged.dropna()\n",
    "    \n",
    "    time_df = pd.read_csv(os.path.join(parent_dir, \"meta\", \"time.csv\"))\n",
    "    start_time = time_df.loc[time_df[\"event\"] == \"START\"][\"system time\"][0]\n",
    "    \n",
    "    merged.reset_index(inplace=True)\n",
    "    merged['time'] = pd.to_datetime(merged['time'] + start_time,unit='s')\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "phyphox_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_combined(path_pp, path_tcx):\n",
    "    pp = read_phyphox(path_pp)\n",
    "    hr = readtcx(path_tcx)\n",
    "    \n",
    "    pp[\"hr\"] = np.nan\n",
    "    \n",
    "    \n",
    "    # Finds the time intervals of the heart rate measurements and update the phyphox heart rate accordingly\n",
    "    # This is done as samsung measurements are not very fine grained and only give use relatively large\n",
    "    # time intervals\n",
    "    for i in range(len(hr) - 1):\n",
    "        row1 = hr.iloc[i]\n",
    "        row2 = hr.iloc[i + 1]\n",
    "        pp.loc[(pp[\"time\"] >= row1[\"time\"].to_datetime64()) & (pp[\"time\"] < row2[\"time\"].to_datetime64()), \"hr\"] = row1[\"hr\"]\n",
    "    \n",
    "    # remove data point without overlap in time\n",
    "    return pp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_combined(\"../data/Lucas/walking2/\", \"../data/Lucas/walking2/walking2.tcx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c5c6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Acceleration figure\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True)\n",
    "\n",
    "fig.suptitle(\"Acceleration\")\n",
    "\n",
    "ax1.plot(df[\"time\"], df[\"acceleration_x\"])\n",
    "ax1.set_ylabel(\"Acceleration x\")\n",
    "\n",
    "ax2.plot(df[\"time\"], df[\"acceleration_y\"])\n",
    "ax2.set_ylabel(\"Acceleration y\")\n",
    "\n",
    "ax3.plot(df[\"time\"], df[\"acceleration_z\"])\n",
    "ax3.set_ylabel(\"Acceleration z\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "fig.align_labels()\n",
    "\n",
    "# Gyroscope figure\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True)\n",
    "\n",
    "fig.suptitle(\"Gyroscope\")\n",
    "\n",
    "ax1.plot(df[\"time\"], df[\"gyroscope_x\"])\n",
    "ax1.set_ylabel(\"Gyroscope x\")\n",
    "\n",
    "ax2.plot(df[\"time\"], df[\"gyroscope_y\"])\n",
    "ax2.set_ylabel(\"Gyroscope y\")\n",
    "\n",
    "ax3.plot(df[\"time\"], df[\"gyroscope_z\"])\n",
    "ax3.set_ylabel(\"Gyroscope z\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "fig.align_labels()\n",
    "\n",
    "# Position figure\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex=True)\n",
    "\n",
    "fig.suptitle(\"Position\")\n",
    "\n",
    "ax1.plot(df[\"time\"], df[\"latitude\"])\n",
    "ax1.set_ylabel(\"Latitude\")\n",
    "\n",
    "ax2.plot(df[\"time\"], df[\"longitude\"])\n",
    "ax2.set_ylabel(\"Longitude\")\n",
    "\n",
    "ax3.plot(df[\"time\"], df[\"height\"])\n",
    "ax3.set_ylabel(\"Height\")\n",
    "\n",
    "ax4.plot(df[\"time\"], df[\"velocity\"])\n",
    "ax4.set_ylabel(\"Velocity\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "fig.align_labels()\n",
    "\n",
    "# Position figure\n",
    "fig, ax = plt.subplots(1, sharex=True)\n",
    "\n",
    "fig.suptitle(\"Heart rate\")\n",
    "\n",
    "ax.plot(df[\"time\"], df[\"hr\"])\n",
    "ax.set_ylabel(\"Heart rate\")\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "fig.align_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0940d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from ML4QS.Python3Code.Chapter4.FrequencyAbstraction import FourierTransformation\n",
    "import re\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Figure 4.1\n",
    "\n",
    "# Sample frequency (Hz)\n",
    "fs = 4\n",
    "\n",
    "# Create time points....\n",
    "#df = pd.DataFrame(np.arange(0, 16.1, float(1)/fs), columns=list('X'))\n",
    "#c1 = 3 * np.sin(2 * math.pi * 0.2 * df['X'])\n",
    "#c2 = 2 * np.sin(2 * math.pi * 0.25 * (df['X']-2)) + 5\n",
    "#df['Y'] = c1 + c2\n",
    "#print(df)\n",
    "\n",
    "# Figure 4.2\n",
    "periodic_predictor_cols = ['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyroscope_x', 'gyroscope_y', 'gyroscope_z']\n",
    "\n",
    "FreqAbs = FourierTransformation()\n",
    "data_table = FreqAbs.abstract_frequency(copy.deepcopy(df), periodic_predictor_cols[3:], 40, fs)\n",
    "# Get the frequencies from the columns....\n",
    "frequencies = []\n",
    "values = []\n",
    "for col in data_table.columns:\n",
    "    val = re.findall(r'freq_\\d+\\.\\d+_Hz', col)\n",
    "    if len(val) > 0:\n",
    "        frequency = float((val[0])[5:len(val)-4])\n",
    "        frequencies.append(frequency)\n",
    "        values.append(data_table.loc[data_table.index, col])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "#plt.xlim([0, 5])\n",
    "ax1.plot(frequencies, values, 'b+')\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel('$a$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a69f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'gyroscope_x_max_freq', 'gyroscope_x_freq_weighted', 'gyroscope_x_pse'\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(data_table['time'], data_table['gyroscope_x_max_freq'])\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(data_table['time'], data_table['gyroscope_x_freq_weighted'])\n",
    "plt.ylim([-3,10])\n",
    "plt.show()\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(data_table['time'], data_table['gyroscope_x_pse'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f0f85",
   "metadata": {},
   "source": [
    "This part is giving me \"ValueError: window must be an integer\" even though I'm doing the same thing as in the example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a883f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ML4QS.Python3Code.Chapter4.TemporalAbstraction import NumericalAbstraction\n",
    "NumAbs = NumericalAbstraction()\n",
    "first_index = df.index[0]\n",
    "milliseconds_per_instance = (df['time'][first_index+1] - df['time'][first_index]).microseconds/1000\n",
    "#milliseconds_per_instance = (df.index[1] - df.index[0]).microseconds/1000\n",
    "#window_sizes = [int(float(5000)/milliseconds_per_instance), int(float(0.5*60000)/milliseconds_per_instance), int(float(5*60000)/milliseconds_per_instance)]\n",
    "              \n",
    "dataset = NumAbs.abstract_numerical(df, ['hr'], 10, 'mean')\n",
    "\n",
    "plt.plot(dataset['hr_temp_mean'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
